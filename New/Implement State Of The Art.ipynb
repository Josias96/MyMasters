{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Of The Art UNET\n",
    "## JA Engelbrecht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "from jupyterthemes import jtplot\n",
    "from skimage.util import montage as montage2d\n",
    "import UNets.MyImplementation.UNET_Adv4 as UNet\n",
    "\n",
    "from MyFunctions.LoadImages import LoadImages\n",
    "from MyFunctions.CreatePaths import CreatePaths\n",
    "from MyFunctions.RunModels import RunModels\n",
    "from CLR.clr_callback import *\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "############ Plot Images/Graphs Functions ############\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list('mycmap', ['black', 'orange', 'red'])\n",
    "\n",
    "\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)\n",
    "mpl.rcParams.update({'font.size': 12})\n",
    "\n",
    "\n",
    "def set_size(width='thesis', fraction=1, subplots=(1, 1)):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float or string\n",
    "            Document width in points, or string of predined document type\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "    subplots: array-like, optional\n",
    "            The number of rows and columns of subplots.\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    if width == 'thesis':\n",
    "        width_pt = 398\n",
    "    else:\n",
    "        width_pt = width\n",
    "\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width_pt * fraction\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    # https://disq.us/p/2940ij3\n",
    "    golden_ratio = (5**.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio * (subplots[0] / subplots[1])\n",
    "\n",
    "    return (fig_width_in, fig_height_in)\n",
    "\n",
    "\n",
    "def showCTImage(IMG, SIZE):\n",
    "    plt.figure(figsize=(SIZE, SIZE))\n",
    "    plt.imshow(IMG, alpha=1, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def showCTMontage(IMG, SIZE):\n",
    "    plt.figure(figsize=(SIZE, SIZE))\n",
    "    plt.imshow(montage2d(IMG), alpha=1, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def showCTMontageOverlay(IMG1, IMG2, SIZE=15, SaveFig=False, save_fig_name=\"\"):\n",
    "    fig, ax = plt.subplots(figsize=(SIZE, SIZE))\n",
    "    try:\n",
    "        ax.imshow(montage2d(IMG1), alpha=1, cmap='gray')\n",
    "    except:\n",
    "        print(\"Error: Img 1\")\n",
    "    try:\n",
    "        ax.imshow(montage2d(IMG2, fill=0), alpha=0.5,\n",
    "                  cmap=cmap, interpolation='none')\n",
    "    except:\n",
    "        print(\"Error: Img 2\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    if SaveFig:\n",
    "        save_fig_path = os.path.join(os.curdir, \"SavedFigures\")\n",
    "        plt.savefig(os.path.join(save_fig_path,\n",
    "                                 save_fig_name+\".pdf\"), bbox_inches='tight')\n",
    "    plt.show()\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Class Variable below for different paths e.g. CT/PET\n",
    "path = CreatePaths(DeviceFlag=\"PC\", ScanTypeFlag=\"CT\", TrainTestFlag=\"Train\")\n",
    "\n",
    "#DATA_PATH = \"D://Masters_Repo//TrainingData//CT_v1\"\n",
    "#IMGS_PATH = path.imgPath()\n",
    "#MSKS_PATH = path.mskPath()\n",
    "#OUTPUT_PATH = path.outputPath()\n",
    "\n",
    "DATA_PATH = \"D://Masters_Repo//TrainingData//CT_v1\"\n",
    "IMGS_PATH = \"D://Masters_Repo//TrainingData//CT_v1//imgs\"\n",
    "MSKS_PATH = \"D://Masters_Repo//TrainingData//CT_v1//masks\"\n",
    "OUTPUT_PATH = \"D://Masters_Repo//Output\"\n",
    "\n",
    "\n",
    "ORIENTATION_ENSEMBLE = [\"Axial\", \"Sagittal\", \"Coronal\"]\n",
    "\n",
    "print(\"Image Path: \"+\"\\t\"+IMGS_PATH+\"\\n\"+\"Mask Path: \" +\n",
    "      \"\\t\"+MSKS_PATH+\"\\n\"+\"Output Path: \"+\"\\t\"+OUTPUT_PATH)\n",
    "\n",
    "ScanType = \"CT\"\n",
    "n_Scans = 60\n",
    "Orientation = \"Axial\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Process Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note to self! Only change ImgDepth in orientaitons other than axial. Otherwise interpolating unnecessarily!!\n",
    "CT_Images = LoadImages(ScanType=ScanType, ScanClass=\"Image\",\n",
    "                       ImgPath=IMGS_PATH, n_Scans=n_Scans, ImgSize=256, ImgDepth=256, Orientation=Orientation).LoadScans()\n",
    "CT_Masks = LoadImages(ScanType=ScanType, ScanClass=\"Mask\",\n",
    "                      MskPath=MSKS_PATH, n_Scans=n_Scans, ImgSize=256, ImgDepth=256, Orientation=Orientation).LoadScans()\n",
    "\n",
    "########################## Split Into Train and Test Set ##########################\n",
    "X, X_Val, y, y_Val = train_test_split(\n",
    "    CT_Images, CT_Masks, test_size=0.15, random_state=42)\n",
    "\n",
    "del CT_Images, CT_Masks\n",
    "\n",
    "y = tf.cast(y, dtype='float32')\n",
    "y_Val = tf.cast(y_Val, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Arrays with a 4'th Singular Dimension (Grayscale Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.expand_dims(X, axis=3)\n",
    "y = np.expand_dims(y, axis=3)\n",
    "X_Val = np.expand_dims(X_Val, axis=3)\n",
    "y_Val = np.expand_dims(y_Val, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Augmentation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAug = dict(rotation_range=15,\n",
    "               zoom_range=0.15,\n",
    "               horizontal_flip=True,\n",
    "               vertical_flip=True)\n",
    "\n",
    "image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**dataAug)\n",
    "mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**dataAug)\n",
    "seed = 42\n",
    "\n",
    "image_datagen.fit(X, augment=True, seed=seed)\n",
    "mask_datagen.fit(y, augment=True, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Augmented Scans Overlayed with Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_Aug = image_datagen.flow(X, batch_size=1, seed=seed)\n",
    "y_Aug = mask_datagen.flow(y, batch_size=1, seed=seed)\n",
    "viewImages = np.zeros((200, 256, 256, 1))\n",
    "viewMasks = np.zeros((200, 256, 256, 1))\n",
    "for i in range(199):\n",
    "    viewImages[i, :, :, :] = X_Aug.next()[0]\n",
    "    viewMasks[i, :, :, :] = y_Aug.next()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "showCTMontageOverlay(IMG1=viewImages[0:199, :, :, 0], IMG2=viewMasks[0:199, :, :, 0],\n",
    "                     SIZE=25, SaveFig=True, save_fig_name=\"Masks on Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to Create U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Functions to Log Training of U-Net ##############\n",
    "def get_run_logdir(root_logdir, input_string):\n",
    "    import time\n",
    "    if not input_string:\n",
    "        run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    else:\n",
    "        run_id = os.path.join(\n",
    "            input_string, time.strftime(\"run_%Y_%m_%d-%H_%M_%S\"))\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "\n",
    "def create_logdir(modelName):\n",
    "    root_logdir = os.path.join(os.curdir, \"My_logs\")\n",
    "    run_logdir = get_run_logdir(root_logdir, modelName)\n",
    "    return run_logdir\n",
    "################################################################\n",
    "\n",
    "########## Custom Loss Function for Dice Coeffiecient ##########\n",
    "# https://towardsdatascience.com/dealing-with-class-imbalanced-image-datasets-1cbd17de76b5\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def tversky(y_true, y_pred, smooth=1, alpha=0.7):\n",
    "    y_true_pos = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_pos = tf.keras.backend.flatten(y_pred)\n",
    "    true_pos = tf.keras.backend.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.keras.backend.sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = tf.keras.backend.sum((1 - y_true_pos) * y_pred_pos)\n",
    "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n",
    "\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true, y_pred)\n",
    "\n",
    "\n",
    "def focal_tversky_loss(y_true, y_pred, gamma=4/3):\n",
    "    tv = tversky(y_true, y_pred)\n",
    "    return tf.keras.backend.pow((1 - tv), gamma)\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModelName = 'U-Net_Adv4_1_' + Orientation\n",
    "MyLogdir = create_logdir(MyModelName)\n",
    "MyModelSaveRoot = os.path.join(os.curdir, \"TrainedModels\")\n",
    "MyModelSavePath = os.path.join(MyModelSaveRoot, MyModelName+\".h5\")\n",
    "\n",
    "print(MyLogdir)\n",
    "print(MyModelSavePath)\n",
    "print(MyModelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learningRates = \"0.001-0.006\"\n",
    "# 1st 0.0005-0.006\n",
    "# 2nd 0.00001-0.0005\n",
    "batch_size = 5\n",
    "\n",
    "steps_p_epoch = np.ceil(X.shape[0]/batch_size)\n",
    "\n",
    "base_lr = 0.00001\n",
    "max_lr = 0.0001\n",
    "csv_logger_cb = tf.keras.callbacks.CSVLogger(\n",
    "    os.path.join(MyModelSaveRoot, MyModelName+\".csv\"), append=True)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(MyModelSavePath,\n",
    "                                                   monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=15, restore_best_weights=True, monitor='val_loss')\n",
    "clr_triangular_cb = CyclicLR(\n",
    "    base_lr=base_lr, max_lr=max_lr, mode='triangular2', step_size=5*X.shape[0])\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(MyLogdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#del MyModel\n",
    "#importlib.reload(UNet)\n",
    "MyModel = UNet.UNet_Adv(input_shape=(256, 256, 1),\n",
    "                        n_filters=64, activation=\"swish\").CreateUnet()\n",
    "MyModel.compile(optimizer=Adam(learning_rate=base_lr),\n",
    "                loss=dice_coef_loss, metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
    "#MyModel.load_weights(\n",
    "#    \"D://Masters_Code_Repo//Josias-Masters//TrainedModels//U-Net_Adv3_Axial.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Compile Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer = \"SGD, Momentum = 0.9, Nestrov = True\"\n",
    "Optimizer = \"Adam\"\n",
    "loss = \"dice_coef_loss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Training Patameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "mask_generator = mask_datagen.flow(y, batch_size=batch_size, seed=seed)\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MyModel.fit(train_generator, steps_per_epoch=steps_p_epoch, epochs=epochs, verbose=1, validation_data=(X_Val, y_Val),\n",
    "            callbacks=[checkpoint_cb, early_stopping_cb, clr_triangular_cb, tensorboard_cb, csv_logger_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModel.fit(X, y, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_Val, y_Val),\n",
    "            callbacks=[checkpoint_cb, early_stopping_cb, clr_triangular_cb, tensorboard_cb, csv_logger_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_triangular_cb._reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MyModel.fit(train_generator, steps_per_epoch=steps_p_epoch, epochs=epochs, verbose=1, validation_data=(X_Val, y_Val),\n",
    "            callbacks=[checkpoint_cb, early_stopping_cb, clr_triangular_cb, tensorboard_cb, csv_logger_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModel.load_weights(MyModelSavePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Model Parameters to Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModelParameters_Strings = [\"ScanType\", \"n_Scans\",\n",
    "                             \"Orientation\", \"Optimizer\", \"Loss\", \"batch_size\", \"epochs\"]\n",
    "MyModelParameters_values = [ScanType, n_Scans,\n",
    "                            Orientation, Optimizer, loss, batch_size, 2*epochs]\n",
    "\n",
    "TextFileName = MyModelName+\".txt\"\n",
    "TextFilePath = os.path.join(os.curdir, \"TrainedModels\", TextFileName)\n",
    "\n",
    "with open(TextFilePath, \"w\") as file:\n",
    "    file.write(\"Parameters for \" + MyModelName + \":\\n\\n\")\n",
    "    for parameter in enumerate(MyModelParameters_Strings):\n",
    "        file.write(parameter[1] + \": \" +\n",
    "                   str(MyModelParameters_values[parameter[0]])+\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Performance on Test Set\n",
    "## View Predicted Images Over Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    y_predict = MyModel.predict(X_Val, batch_size=10, verbose=1)\n",
    "except:\n",
    "    X_Val = np.squeeze(X_Val)\n",
    "    print(\"Error: Input to Model has to be 4D (x, y, x, 1)\")\n",
    "    print(\"Reshaping..\")\n",
    "    X_Val = np.expand_dims(X_Val, axis=3)\n",
    "    y_predict = MyModel.predict(X_Val, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predict = np.squeeze(y_predict)\n",
    "X_Val = np.squeeze(X_Val)\n",
    "\n",
    "try:\n",
    "    X_Val = np.squeeze(X_Val)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    y_threshold = np.squeeze(y_threshold)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    y_Val = np.squeeze(y_Val)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "y_new = np.ma.masked_where(y_predict > 0, y_predict, copy=False)\n",
    "\n",
    "showCTMontageOverlay(IMG1=X_Val[0:150, :, :],\n",
    "                     IMG2=y_predict[0:150, :, :], SIZE=25, SaveFig=True, save_fig_name=\"Predicted Masks on Actual Masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Performance on Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestImage, Orig_Size, MetaData = LoadImages(ScanType=\"CT\", ScanClass=\"Image\", ScanName=\"CB_091_CT_M0.nii.gz\",\n",
    "                                            ImgPath=\"D://Masters_Repo//TestingData//CT_v1//imgs\", Orientation=Orientation).LoadScan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunModels(OutPath=OUTPUT_PATH, ScanName=\"PCB_091_CT_M0_vx\", Scan=TestImage, Scan_Size=Orig_Size,\n",
    "          Scan_Metadata=MetaData, Model=MyModel, Orientation=Orientation).runModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
