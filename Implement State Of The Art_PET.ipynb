{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Of The Art UNET\n",
    "## JA Engelbrecht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "from jupyterthemes import jtplot\n",
    "from skimage.util import montage as montage2d\n",
    "import UNets.MyImplementation.UNET_Adv7 as UNet\n",
    "\n",
    "from MyFunctions.learningRateFunction import LRFinder\n",
    "from MyFunctions.CreatePaths import CreatePaths\n",
    "from MyFunctions.LoadImages import LoadImages\n",
    "from MyFunctions.RunModels import RunModels\n",
    "\n",
    "from CLR.clr_callback import *\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "############ Plot Images/Graphs Functions ############\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list('mycmap', ['black', 'orange', 'red'])\n",
    "\n",
    "\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)\n",
    "mpl.rcParams.update({'font.size': 12})\n",
    "\n",
    "\n",
    "def set_size(width='thesis', fraction=1, subplots=(1, 1)):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float or string\n",
    "            Document width in points, or string of predined document type\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "    subplots: array-like, optional\n",
    "            The number of rows and columns of subplots.\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    if width == 'thesis':\n",
    "        width_pt = 398\n",
    "    else:\n",
    "        width_pt = width\n",
    "\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width_pt * fraction\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    # https://disq.us/p/2940ij3\n",
    "    golden_ratio = (5**.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio * (subplots[0] / subplots[1])\n",
    "\n",
    "    return (fig_width_in, fig_height_in)\n",
    "\n",
    "\n",
    "def showCTImage(IMG, SIZE):\n",
    "    plt.figure(figsize=(SIZE, SIZE))\n",
    "    plt.imshow(IMG, alpha=1, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def showCTMontage(IMG, SIZE, SaveFig=False, save_fig_name=\"\"):\n",
    "    plt.figure(figsize=(SIZE, SIZE))\n",
    "    plt.imshow(montage2d(IMG), alpha=1, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    if SaveFig:\n",
    "        save_fig_path = os.path.join(os.curdir, \"SavedFigures\")\n",
    "        plt.savefig(os.path.join(save_fig_path,\n",
    "                                 save_fig_name+\".pdf\"), bbox_inches='tight')\n",
    "\n",
    "\n",
    "def showCTMontageOverlay(IMG1, IMG2, SIZE=15, SaveFig=False, save_fig_name=\"\"):\n",
    "    fig, ax = plt.subplots(figsize=(SIZE, SIZE))\n",
    "    try:\n",
    "        ax.imshow(montage2d(IMG1), alpha=1, cmap='gray')\n",
    "    except:\n",
    "        print(\"Error: Img 1\")\n",
    "    try:\n",
    "        ax.imshow(montage2d(IMG2, fill=0), alpha=0.5,\n",
    "                  cmap=cmap, interpolation='none')\n",
    "    except:\n",
    "        print(\"Error: Img 2\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    if SaveFig:\n",
    "        save_fig_path = os.path.join(os.curdir, \"SavedFigures\")\n",
    "        plt.savefig(os.path.join(save_fig_path,\n",
    "                                 save_fig_name+\".pdf\"), bbox_inches='tight')\n",
    "    plt.show()\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Class Variable below for different paths e.g. CT/PET\n",
    "#path = CreatePaths(DeviceFlag=\"PC\", ScanTypeFlag=\"CT\", TrainTestFlag=\"Train\")\n",
    "\n",
    "#DATA_PATH = \"D://Masters_Repo//TrainingData//CT_v1\"\n",
    "#IMGS_PATH = path.imgPath()\n",
    "#MSKS_PATH = path.mskPath()\n",
    "#OUTPUT_PATH = path.outputPath()\n",
    "\n",
    "DATA_PATH = \"F://Masters_Repo//TrainingData//PET\"\n",
    "IMGS_PATH = \"F://Masters_Repo//TrainingData//PET//imgs\"\n",
    "MSKS_PATH = \"F://Masters_Repo//TrainingData//PET//masks_v2\"\n",
    "OUTPUT_PATH = \"F://Masters_Repo//Output\"\n",
    "\n",
    "ORIENTATION_ENSEMBLE = [\"Axial\", \"Sagittal\", \"Coronal\"]\n",
    "\n",
    "print(\"Image Path: \"+\"\\t\"+IMGS_PATH+\"\\n\"+\"Mask Path: \" +\n",
    "      \"\\t\"+MSKS_PATH+\"\\n\"+\"Output Path: \"+\"\\t\"+OUTPUT_PATH)\n",
    "\n",
    "ScanType = \"PET\"\n",
    "n_Scans = 10\n",
    "Orientation = \"Coronal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Process Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note to self! Only change ImgDepth in orientaitons other than axial. Otherwise interpolating unnecessarily!!\n",
    "PET_Images = LoadImages(ScanType=ScanType, ScanClass=\"Image\",\n",
    "                       ImgPath=IMGS_PATH, n_Scans=n_Scans, ImgSize=256, ImgDepth=256, Orientation=Orientation).LoadScans()\n",
    "PET_Masks = LoadImages(ScanType=ScanType, ScanClass=\"Mask\",\n",
    "                      MskPath=MSKS_PATH, n_Scans=n_Scans, ImgSize=256, ImgDepth=256, Orientation=Orientation).LoadScans()\n",
    "\n",
    "########################## Split Into Train and Test Set ##########################\n",
    "X, X_Val, y, y_Val = train_test_split(\n",
    "    PET_Images, PET_Masks, test_size=0.15, random_state=42)\n",
    "\n",
    "del PET_Images, PET_Masks\n",
    "\n",
    "y = tf.cast(y, dtype='float32')\n",
    "y_Val = tf.cast(y_Val, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Arrays with a 4'th Singular Dimension (Grayscale Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.expand_dims(X, axis=3)\n",
    "y = np.expand_dims(y, axis=3)\n",
    "X_Val = np.expand_dims(X_Val, axis=3)\n",
    "y_Val = np.expand_dims(y_Val, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Augmentation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAug = dict(rotation_range=15,\n",
    "               zoom_range=0.15,\n",
    "               horizontal_flip=True,\n",
    "               vertical_flip=True)\n",
    "\n",
    "image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**dataAug)\n",
    "mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**dataAug)\n",
    "seed = 42\n",
    "\n",
    "image_datagen.fit(X, augment=True, seed=seed)\n",
    "mask_datagen.fit(y, augment=True, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Augmented Scans Overlayed with Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_Aug = image_datagen.flow(X, batch_size=1, seed=seed)\n",
    "y_Aug = mask_datagen.flow(y, batch_size=1, seed=seed)\n",
    "viewImages = np.zeros((200, 256, 256, 1))\n",
    "viewMasks = np.zeros((200, 256, 256, 1))\n",
    "for i in range(199):\n",
    "    viewImages[i, :, :, :] = X_Aug.next()[0]\n",
    "    viewMasks[i, :, :, :] = y_Aug.next()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "showCTMontageOverlay(IMG1=viewImages[0:199, :, :, 0], IMG2=viewMasks[0:199, :, :, 0],\n",
    "                     SIZE=25, SaveFig=False, save_fig_name=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to Create U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Functions to Log Training of U-Net ##############\n",
    "def get_run_logdir(root_logdir, input_string):\n",
    "    import time\n",
    "    if not input_string:\n",
    "        run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    else:\n",
    "        run_id = os.path.join(\n",
    "            input_string, time.strftime(\"run_%Y_%m_%d-%H_%M_%S\"))\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "\n",
    "def create_logdir(modelName):\n",
    "    root_logdir = os.path.join(os.curdir, \"My_logs\")\n",
    "    run_logdir = get_run_logdir(root_logdir, modelName)\n",
    "    return run_logdir\n",
    "################################################################\n",
    "\n",
    "########## Custom Loss Function for Dice Coeffiecient ##########\n",
    "# https://towardsdatascience.com/dealing-with-class-imbalanced-image-datasets-1cbd17de76b5\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def tversky(y_true, y_pred, smooth=1, alpha=0.7):\n",
    "    y_true_pos = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_pos = tf.keras.backend.flatten(y_pred)\n",
    "    true_pos = tf.keras.backend.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.keras.backend.sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = tf.keras.backend.sum((1 - y_true_pos) * y_pred_pos)\n",
    "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n",
    "\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true, y_pred)\n",
    "\n",
    "\n",
    "def focal_tversky_loss(y_true, y_pred, gamma=4/3):\n",
    "    tv = tversky(y_true, y_pred)\n",
    "    return tf.keras.backend.pow((1 - tv), gamma)\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Admin.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModelName = 'PET_3_1_'+ Orientation\n",
    "MyLogdir = create_logdir(MyModelName)\n",
    "MyModelSaveRoot = os.path.join(os.curdir, \"TrainedModels\")\n",
    "MyModelSavePath = os.path.join(MyModelSaveRoot, MyModelName+\".h5\")\n",
    "\n",
    "print(MyLogdir)\n",
    "print(MyModelSavePath)\n",
    "print(MyModelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del MyModel\n",
    "# importlib.reload(UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "MyModel = UNet.UNet_Adv(input_shape=(256, 256, 1),\n",
    "                        n_filters=32, activation=tf.keras.layers.LeakyReLU()).CreateUnet()\n",
    "MyModel.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                loss=focal_tversky_loss, metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
    "MyModel.load_weights(\n",
    "    \"F://MyMasters//Code//MyCode//TrainedModels//PET_3_0_Axial.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger_cb = tf.keras.callbacks.CSVLogger(\n",
    "    os.path.join(MyModelSaveRoot, MyModelName+\".csv\"), append=True)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(MyModelSavePath,\n",
    "                                                   monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=15, restore_best_weights=True, monitor='val_loss')\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(MyLogdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Proper Range for the Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "steps_p_epoch = np.ceil(1000/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use small subset of data\n",
    "image_generator = image_datagen.flow(\n",
    "    X[0:1000, :, :, :], batch_size=batch_size, seed=seed)\n",
    "mask_generator = mask_datagen.flow(\n",
    "    y[0:1000, :, :, :], batch_size=batch_size, seed=seed)\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = LRFinder(min_lr=1e-5, max_lr=1e-2,\n",
    "                     steps_per_epoch=steps_p_epoch, epochs=3)\n",
    "MyModel.fit(train_generator, steps_per_epoch=steps_p_epoch,\n",
    "            epochs=3, verbose=1, callbacks=[lr_finder])\n",
    "lr_finder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learningRates = \"0.001-0.006\"\n",
    "# 1st 0.0005-0.006\n",
    "# 2nd 0.00001-0.0005\n",
    "\n",
    "#Defaults\n",
    "#base_lr = 4e-4\n",
    "#max_lr = 1e-3\n",
    "\n",
    "#PET 2_0\n",
    "base_lr = 1e-4\n",
    "max_lr = 1e-3\n",
    "\n",
    "clr_triangular_cb = CyclicLR(\n",
    "    base_lr=base_lr, max_lr=max_lr, mode='triangular2', step_size=5*X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Compile Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer = \"SGD, Momentum = 0.9, Nestrov = True\"\n",
    "Optimizer = \"Adam\"\n",
    "loss = \"focal_tversky_loss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Training Patameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_p_epoch = np.ceil(X.shape[0]/batch_size)\n",
    "image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "mask_generator = mask_datagen.flow(y, batch_size=batch_size, seed=seed)\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MyModel.fit(train_generator, steps_per_epoch=steps_p_epoch, epochs=epochs, verbose=1, validation_data=(X_Val, y_Val),\n",
    "            callbacks=[checkpoint_cb, early_stopping_cb, clr_triangular_cb, tensorboard_cb, csv_logger_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MyModel.load_weights(MyModelSavePath)\n",
    "clr_triangular_cb._reset()\n",
    "base_lr = 1e-5\n",
    "max_lr = 1e-4\n",
    "clr_triangular_cb = CyclicLR(\n",
    "    base_lr=base_lr, max_lr=max_lr, mode='triangular2', step_size=5*X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MyModel.fit(train_generator, steps_per_epoch=steps_p_epoch, epochs=epochs, verbose=1, validation_data=(X_Val, y_Val),\n",
    "            callbacks=[checkpoint_cb, early_stopping_cb, clr_triangular_cb, tensorboard_cb, csv_logger_cb])"
   ]
  },
  {
   "source": [
    "MyModel.fit(X, y, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_Val, y_Val),\n",
    "            callbacks=[checkpoint_cb, early_stopping_cb, clr_triangular_cb, tensorboard_cb, csv_logger_cb])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_triangular_cb._reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModel.load_weights(MyModelSavePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Model Parameters to Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModelParameters_Strings = [\"ScanType\", \"n_Scans\",\n",
    "                             \"Orientation\", \"Optimizer\", \"Loss\", \"batch_size\", \"epochs\"]\n",
    "MyModelParameters_values = [ScanType, n_Scans,\n",
    "                            Orientation, Optimizer, loss, batch_size, 5]\n",
    "\n",
    "TextFileName = MyModelName+\".txt\"\n",
    "TextFilePath = os.path.join(os.curdir, \"TrainedModels\", TextFileName)\n",
    "\n",
    "with open(TextFilePath, \"w\") as file:\n",
    "    file.write(\"Parameters for \" + MyModelName + \":\\n\\n\")\n",
    "    for parameter in enumerate(MyModelParameters_Strings):\n",
    "        file.write(parameter[1] + \": \" +\n",
    "                   str(MyModelParameters_values[parameter[0]])+\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Performance on Test Set\n",
    "## View Predicted Images Over Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    y_predict = MyModel.predict(X_Val, batch_size=10, verbose=1)\n",
    "except:\n",
    "    X_Val = np.squeeze(X_Val)\n",
    "    print(\"Error: Input to Model has to be 4D (x, y, x, 1)\")\n",
    "    print(\"Reshaping..\")\n",
    "    X_Val = np.expand_dims(X_Val, axis=3)\n",
    "    y_predict = MyModel.predict(X_Val, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predict = np.squeeze(y_predict)\n",
    "X_Val = np.squeeze(X_Val)\n",
    "\n",
    "try:\n",
    "    X_Val = np.squeeze(X_Val)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    y_threshold = np.squeeze(y_threshold)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    y_Val = np.squeeze(y_Val)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "y_new = np.ma.masked_where(y_predict > 0, y_predict, copy=False)\n",
    "\n",
    "showCTMontageOverlay(IMG1=X_Val[0:250, :, :],\n",
    "                     IMG2=y_predict[0:250, :, :], SIZE=25, SaveFig=False, save_fig_name=\"Predicted Masks on Actual Masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Performance on Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del LoadImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScanName = \"CB_086_PET_M0\"\n",
    "TestImage, Orig_Size, MetaData = LoadImages(ScanType=\"PET\", ScanClass=\"Image\", ScanName=ScanName+\".nii\",\n",
    "                                            ImgPath=\"F:\\\\Masters_Repo\\\\TestingData\", Orientation=Orientation).LoadScan()\n",
    "RunModels(OutPath=OUTPUT_PATH, ScanName=\"P\"+ScanName, Scan=TestImage, Scan_Size=Orig_Size,\n",
    "          Scan_Metadata=MetaData, Model=MyModel, Orientation=Orientation).runModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Orig_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('MyMasters': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d8265bed6799d0b3fba5aa1cccc33d22252c6f1298c52c648030eb5f7a945c4b"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}