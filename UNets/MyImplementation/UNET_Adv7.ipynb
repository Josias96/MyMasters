{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import DepthwiseConv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "\n",
    "def swish(x):\n",
    "    #Hard Swish from \"Searching for MobileNetV3\"\n",
    "    return (x * (tf.nn.relu6(x+3) / 6))\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "class UNet_Adv:\n",
    "    def __init__(self, input_shape,n_filters,showSummary=True, activation=\"relu\"):\n",
    "        self.input_shape = input_shape\n",
    "        self.showSummary = showSummary\n",
    "        self.n_filters = n_filters\n",
    "        self.activation = activation\n",
    "    \n",
    "    def Conv2D_TailBlock(self,input_tensor, kernel_size, filters, skipcon=True):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                    kernel_initializer=\"he_normal\", padding=\"same\")(input_tensor)        \n",
    "        conv = Activation(self.activation)(conv)\n",
    "        conv = BatchNormalization(renorm=True)(conv)\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                    kernel_initializer=\"he_normal\", padding=\"same\")(conv)\n",
    "        conv = BatchNormalization(renorm=True)(conv)\n",
    "         #----------- Residual Block --------------\n",
    "        if skipcon:\n",
    "            conv_in = Conv2D(filters=filters, kernel_size=(1,1),\n",
    "                        kernel_initializer=\"he_normal\", padding=\"same\")(input_tensor)\n",
    "            conv_in = Activation(self.activation)(conv_in)\n",
    "            conv_in = BatchNormalization(renorm=True)(conv_in)\n",
    "            out = tf.keras.layers.Add()([conv, conv_in])\n",
    "        else:\n",
    "            out = conv\n",
    "        #-----------------------------------------\n",
    "        out = Activation(self.activation)(out)\n",
    "        out = BatchNormalization(renorm=True)(out)     \n",
    "        return out\n",
    "\n",
    "    def Conv2D_Block(self,input_tensor, kernel_size, filters, n_layers, dropout, skipcon=True):\n",
    "        #----------- BottleNeck --------------\n",
    "        conv_in = Conv2D(filters=filters, kernel_size=(1,1),\n",
    "                    kernel_initializer=\"he_normal\", padding=\"same\")(input_tensor)\n",
    "        conv_in = Activation(self.activation)(conv_in)\n",
    "        conv_in = BatchNormalization(renorm=True)(conv_in)\n",
    "        if n_layers == 4:\n",
    "            conv = self.DenseNet_Block_4(conv_in, kernel_size, filters)\n",
    "        elif n_layers == 5:\n",
    "            conv = self.DenseNet_Block_5(conv_in, kernel_size, filters)\n",
    "        elif n_layers == 7:\n",
    "            conv = self.DenseNet_Block_7(conv_in, kernel_size, filters)\n",
    "        elif n_layers == 10:\n",
    "            conv = self.DenseNet_Block_10(conv_in, kernel_size, filters)\n",
    "        elif n_layers == 12:\n",
    "            conv = self.DenseNet_Block_12(conv_in, kernel_size, filters)\n",
    "        elif n_layers == 15:\n",
    "            conv = self.DenseNet_Block_15(conv_in, kernel_size,filters)\n",
    "        else:\n",
    "            print(\"Error with DenseNet_Blocks. Confirm n_layers is one of:\\n 4, 5, 7, 10, 12, 15\")\n",
    "        #----------- Residual Block --------------\n",
    "        if skipcon:\n",
    "            out = tf.keras.layers.Add()([conv_in, conv])\n",
    "            out = Activation(self.activation)(out)\n",
    "            out = BatchNormalization(renorm=True)(out)   \n",
    "        else:\n",
    "            out = conv\n",
    "        #-----------------------------------------\n",
    "        out = SpatialDropout2D(dropout)(out)\n",
    "        return out\n",
    "\n",
    "    def DenseNet_Chunk(self,input_tensor, kernel_size,BatchNorm=True, activation=True):\n",
    "        DC_In = DepthwiseConv2D(depth_multiplier=1, kernel_size=kernel_size,\n",
    "                    kernel_initializer=\"he_normal\", padding=\"same\")(input_tensor)\n",
    "        if activation:\n",
    "            DC_In = Activation(self.activation)(DC_In)\n",
    "        if BatchNorm:\n",
    "            DC_In = BatchNormalization(renorm=True)(DC_In)\n",
    "        DC_Out = tf.keras.layers.Add()([DC_In, input_tensor])\n",
    "        DC_Out = Activation(self.activation)(DC_Out)\n",
    "        DC_Out = BatchNormalization(renorm=True)(DC_Out)   \n",
    "        return DC_Out, DC_In\n",
    "\n",
    "    def DenseNet_Block_4(self,input_tensor, kernel_size, filters):\n",
    "        DN_1, DN_A = self.DenseNet_Chunk(input_tensor, kernel_size)\n",
    "        DN_2, DN_B = self.DenseNet_Chunk(DN_1, kernel_size)\n",
    "        DN_3, DN_C = self.DenseNet_Chunk(DN_2, kernel_size)\n",
    "        DN_Out = DepthwiseConv2D(depth_multiplier=1, kernel_size=kernel_size,\n",
    "                    kernel_initializer=\"he_normal\", padding=\"same\")(DN_3)\n",
    "        DN_Out = BatchNormalization(renorm=True)(DN_Out)\n",
    "        DN_Out = tf.keras.layers.Add()([DN_Out, DN_A, DN_B, DN_C])\n",
    "        return DN_Out\n",
    "\n",
    "    def DenseNet_Block_5(self,input_tensor, kernel_size, filters):\n",
    "        DN_1, DN_A = self.DenseNet_Chunk(input_tensor, kernel_size)\n",
    "        DN_2, DN_B = self.DenseNet_Chunk(DN_1, kernel_size)\n",
    "        DN_3, DN_C = self.DenseNet_Chunk(DN_2, kernel_size)\n",
    "        DN_4, DN_D = self.DenseNet_Chunk(DN_3, kernel_size)\n",
    "        DN_Out = DepthwiseConv2D(depth_multiplier=1, kernel_size=kernel_size,\n",
    "                    kernel_initializer=\"he_normal\", padding=\"same\")(DN_4)\n",
    "        DN_Out = BatchNormalization(renorm=True)(DN_Out)\n",
    "        DN_Out = tf.keras.layers.Add()([DN_Out, DN_A, DN_B, DN_C, DN_D])\n",
    "        return DN_Out\n",
    "\n",
    "    def DenseNet_Block_7(self,input_tensor, kernel_size, filters):\n",
    "        DN_1, DN_A = self.DenseNet_Chunk(input_tensor, kernel_size)\n",
    "        DN_2, DN_B = self.DenseNet_Chunk(DN_1, kernel_size)\n",
    "        DN_3, DN_C = self.DenseNet_Chunk(DN_2, kernel_size)\n",
    "        DN_4, DN_D = self.DenseNet_Chunk(DN_3, kernel_size)\n",
    "        DN_5, DN_E = self.DenseNet_Chunk(DN_4, kernel_size)\n",
    "        DN_6, DN_F = self.DenseNet_Chunk(DN_5, kernel_size)\n",
    "        DN_Out = DepthwiseConv2D(depth_multiplier=1, kernel_size=kernel_size,\n",
    "                    kernel_initializer=\"he_normal\", padding=\"same\")(DN_6)\n",
    "        DN_Out = BatchNormalization(renorm=True)(DN_Out)\n",
    "        DN_Out = tf.keras.layers.Add()([DN_Out, DN_A, DN_B, DN_C, DN_D, DN_E, DN_F])\n",
    "        return DN_Out\n",
    "\n",
    "    def DenseNet_Block_10(self,input_tensor, kernel_size, filters):\n",
    "        conv_in = Conv2D(filters=np.int(filters/2), kernel_size=(1,1),\n",
    "                        kernel_initializer=\"he_normal\", padding=\"same\")(input_tensor)\n",
    "        conv_in = Activation(self.activation)(conv_in)\n",
    "        conv_in = BatchNormalization(renorm=True)(conv_in)\n",
    "\n",
    "        DN_1, DN_A = self.DenseNet_Chunk(input_tensor, kernel_size)\n",
    "        DN_2, DN_B = self.DenseNet_Chunk(DN_1, kernel_size)\n",
    "        DN_3, DN_C = self.DenseNet_Chunk(DN_2, kernel_size)\n",
    "        DN_4, DN_D = self.DenseNet_Chunk(DN_3, kernel_size)\n",
    "        DN_5, DN_E = self.DenseNet_Chunk(DN_4, kernel_size)\n",
    "        DN_6, DN_F = self.DenseNet_Chunk(DN_5, kernel_size)\n",
    "        DN_7, DN_G = self.DenseNet_Chunk(DN_6, kernel_size)\n",
    "        DN_8, DN_H = self.DenseNet_Chunk(DN_7, kernel_size)\n",
    "        DN_9, DN_I = self.DenseNet_Chunk(DN_8, kernel_size)\n",
    "        DN_Out = DepthwiseConv2D(depth_multiplier=1, kernel_size=kernel_size,\n",
    "                    kernel_initializer=\"he_normal\", padding=\"same\")(DN_9)\n",
    "        DN_Out = BatchNormalization(renorm=True)(DN_Out)\n",
    "        DN_Out = tf.keras.layers.Add()([DN_Out, DN_A, DN_B, DN_C, DN_D, DN_E, DN_F, DN_G, DN_H, DN_I])\n",
    "\n",
    "        conv_out = Conv2D(filters=filters, kernel_size=(1,1),\n",
    "                        kernel_initializer=\"he_normal\", padding=\"same\")(DN_Out)\n",
    "        conv_out = Activation(self.activation)(conv_out)\n",
    "        conv_out = BatchNormalization(renorm=True)(conv_out)\n",
    "        return DN_Out\n",
    "\n",
    "    def UpConvolution(self,input_tensor, skip_tensor, kernel_size, filters):\n",
    "        upconv = Conv2D(filters=filters, kernel_size=kernel_size, kernel_initializer=\"he_normal\",\n",
    "                        padding=\"same\")(UpSampling2D(size=(2,2))(input_tensor))\n",
    "        upconv = Activation(self.activation)(upconv)\n",
    "        upconv = BatchNormalization(renorm=True)(upconv)\n",
    "        upconv = concatenate([upconv, skip_tensor])\n",
    "        return upconv\n",
    "\n",
    "    def CreateUnet(self):\n",
    "\n",
    "        input_layer = Input(self.input_shape)\n",
    "\n",
    "        c1 = self.Conv2D_TailBlock(input_layer, kernel_size=(3, 3), filters=self.n_filters)\n",
    "        p1 = MaxPool2D(pool_size=(2, 2), name=\"p1\")(c1)\n",
    "\n",
    "        c2 = self.Conv2D_Block(p1, kernel_size=(3, 3), filters=self.n_filters*2, n_layers=4, dropout=0.15)\n",
    "        p2 = MaxPool2D(pool_size=(2, 2), name=\"p2\")(c2)\n",
    "\n",
    "        c3 = self.Conv2D_Block(p2, kernel_size=(3, 3), filters=self.n_filters*4, n_layers=5, dropout=0.15)\n",
    "        p3 = MaxPool2D(pool_size=(2, 2), name=\"p3\")(c3)\n",
    "\n",
    "        c4 = self.Conv2D_Block(p3, kernel_size=(3, 3), filters=self.n_filters*8, n_layers=7, dropout=0.15)\n",
    "        p4 = MaxPool2D(pool_size=(2, 2), name=\"p4\")(c4)\n",
    "\n",
    "        c5 = self.Conv2D_Block(p4, kernel_size=(3, 3), filters=self.n_filters*16, n_layers=10, dropout=0.15)\n",
    "\n",
    "        u1 = self.UpConvolution(c5, c4, kernel_size=(3, 3), filters=self.n_filters*8)\n",
    "        c6 = self.Conv2D_Block(u1, kernel_size=(3, 3), filters=self.n_filters*8, n_layers=7, dropout=0.15)\n",
    "\n",
    "        u2 = self.UpConvolution(c6, c3, kernel_size=(3, 3), filters=self.n_filters*4)\n",
    "        c7 = self.Conv2D_Block(u2, kernel_size=(3, 3), filters=self.n_filters*4, n_layers=5, dropout=0.15)\n",
    "\n",
    "        u3 = self.UpConvolution(c7, c2, kernel_size=(3, 3), filters=self.n_filters*2)\n",
    "        c8 = self.Conv2D_Block(u3, kernel_size=(3, 3),filters=self.n_filters*2, n_layers=4, dropout=0.15)\n",
    "\n",
    "        u4 = self.UpConvolution(c8, c1, kernel_size=(3, 3), filters=self.n_filters)\n",
    "        c9 = self.Conv2D_TailBlock(u4, kernel_size=(3, 3), filters=self.n_filters)\n",
    "\n",
    "        output_layer = Conv2D(filters=1, kernel_size=(1, 1),\n",
    "                            activation=\"sigmoid\", name=\"OutLayer\")(c9)\n",
    "\n",
    "        MyModel = tensorflow.keras.models.Model(\n",
    "            inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        if self.showSummary:\n",
    "            MyModel.summary()\n",
    "        return MyModel\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
