{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Vanilla U-Net\n",
    "## Author:  JA Engelbrecht\n",
    "## Supervisor:  Prof Martin Nieuwoudt\n",
    "## Co-supervisor: Dr ST Malherbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "from jupyterthemes import jtplot\n",
    "from skimage.util import montage as montage2d\n",
    "import UNets.Vanilla.UNet_Vanilla as UNet\n",
    "\n",
    "from MyFunctions.learningRateFunction import LRFinder\n",
    "from MyFunctions.LoadImages import LoadImages\n",
    "from MyFunctions.CreatePaths import CreatePaths\n",
    "from CLR.clr_callback import *\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "############ Plot Images/Graphs Functions ############\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "cmap = LinearSegmentedColormap.from_list('mycmap', ['black', 'orange', 'red'])\n",
    "\n",
    "\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)\n",
    "mpl.rcParams.update({'font.size': 12})\n",
    "\n",
    "\n",
    "def set_size(width='thesis', fraction=1, subplots=(1, 1)):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float or string\n",
    "            Document width in points, or string of predined document type\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "    subplots: array-like, optional\n",
    "            The number of rows and columns of subplots.\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    if width == 'thesis':\n",
    "        width_pt = 398\n",
    "    else:\n",
    "        width_pt = width\n",
    "\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width_pt * fraction\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    # https://disq.us/p/2940ij3\n",
    "    golden_ratio = (5**.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio * (subplots[0] / subplots[1])\n",
    "\n",
    "    return (fig_width_in, fig_height_in)\n",
    "\n",
    "\n",
    "def showCTImage(IMG, SIZE):\n",
    "    plt.figure(figsize=(SIZE, SIZE))\n",
    "    plt.imshow(IMG, alpha=1, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def showCTMontage(IMG, SIZE):\n",
    "    plt.figure(figsize=(SIZE, SIZE))\n",
    "    plt.imshow(montage2d(IMG), alpha=1, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def showCTMontageOverlay(IMG1, IMG2, SIZE=15, SaveFig=False, save_fig_name=\"\"):\n",
    "    fig, ax = plt.subplots(figsize=(SIZE, SIZE))\n",
    "    try:\n",
    "        ax.imshow(montage2d(IMG1), alpha=1, cmap='gray')\n",
    "    except:\n",
    "        print(\"Error: Img 1\")\n",
    "    try:\n",
    "        ax.imshow(montage2d(IMG2, fill=0), alpha=0.5,\n",
    "                  cmap=cmap, interpolation='none')\n",
    "    except:\n",
    "        print(\"Error: Img 2\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    if SaveFig:\n",
    "        save_fig_path = os.path.join(os.curdir, \"SavedFigures\")\n",
    "        plt.savefig(os.path.join(save_fig_path,\n",
    "                                 save_fig_name+\".pdf\"), bbox_inches='tight')\n",
    "    plt.show()\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Class Variable below for different paths e.g. CT/PET\n",
    "path = CreatePaths(DeviceFlag=\"PC\", ScanTypeFlag=\"CT\", TrainTestFlag=\"Train\")\n",
    "\n",
    "#DATA_PATH = \"D://Masters_Repo//TrainingData//CT_v1\"\n",
    "#IMGS_PATH = path.imgPath()\n",
    "#MSKS_PATH = path.mskPath()\n",
    "#OUTPUT_PATH = path.outputPath()\n",
    "\n",
    "DATA_PATH = \"F://MyMasters//Data//TrainingData\"\n",
    "IMGS_PATH = \"F://MyMasters//Data//TrainingData//imgs\"\n",
    "MSKS_PATH = \"F://MyMasters//Data//TrainingData//masks\"\n",
    "OUTPUT_PATH = \"F://MyMasters//Output\"\n",
    "\n",
    "ORIENTATION_ENSEMBLE = [\"Axial\", \"Sagittal\", \"Coronal\"]\n",
    "\n",
    "print(\"Image Path: \"+\"\\t\"+IMGS_PATH+\"\\n\"+\"Mask Path: \" +\n",
    "      \"\\t\"+MSKS_PATH+\"\\n\"+\"Output Path: \"+\"\\t\"+OUTPUT_PATH)\n",
    "\n",
    "ScanType = \"CT\"\n",
    "n_Scans = 72\n",
    "Orientation = \"Axial\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Process Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ScanType = \"CT\"\n",
    "n_Scans = 72\n",
    "Orientation = \"Axial\"\n",
    "\n",
    "CT_Images = LoadImages(ScanType=ScanType, ScanClass=\"Image\",\n",
    "                       ImgPath=IMGS_PATH, n_Scans=n_Scans, Orientation=Orientation).LoadScans()\n",
    "CT_Masks = LoadImages(ScanType=ScanType, ScanClass=\"Mask\",\n",
    "                      MskPath=MSKS_PATH, n_Scans=n_Scans, Orientation=Orientation).LoadScans()\n",
    "\n",
    "########################## Split Into Train and Test Set ##########################\n",
    "X, X_Val, y, y_Val = train_test_split(\n",
    "    CT_Images, CT_Masks, test_size=0.15, random_state=42)\n",
    "\n",
    "del CT_Images, CT_Masks\n",
    "\n",
    "y = tf.cast(y, dtype='float32')\n",
    "y_Val = tf.cast(y_Val, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Imported Scans Overlayed with Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mask = np.copy(y)\n",
    "y_mask = np.ma.masked_where(y == 0.5, y, copy=False)\n",
    "showCTMontageOverlay(IMG1=X[500:564, :, :], IMG2=y[500:564, :, :],\n",
    "                     SIZE=25, SaveFig=True, save_fig_name=\"Masks on Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Arrays with a 4'th Singular Dimension (Grayscale Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = np.expand_dims(X, axis=3)\n",
    "y = np.expand_dims(y, axis=3)\n",
    "X_Val = np.expand_dims(X_Val, axis=3)\n",
    "y_Val = np.expand_dims(y_Val, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAug = dict(rotation_range=15,\n",
    "               zoom_range=0.15,\n",
    "               horizontal_flip=True,\n",
    "               vertical_flip=True)\n",
    "\n",
    "image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**dataAug)\n",
    "mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**dataAug)\n",
    "seed = 42\n",
    "\n",
    "image_datagen.fit(X, augment=True, seed=seed)\n",
    "mask_datagen.fit(y, augment=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Aug = image_datagen.flow(X, batch_size=1, seed=seed)\n",
    "y_Aug = mask_datagen.flow(y, batch_size=1, seed=seed)\n",
    "viewImages = np.zeros((200, 256, 256, 1))\n",
    "viewMasks = np.zeros((200, 256, 256, 1))\n",
    "for i in range(199):\n",
    "    viewImages[i, :, :, :] = X_Aug.next()[0]\n",
    "    viewMasks[i, :, :, :] = y_Aug.next()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "showCTMontageOverlay(IMG1=viewImages[0:199, :, :, 0], IMG2=viewMasks[0:199, :, :, 0],\n",
    "                     SIZE=25, SaveFig=False, save_fig_name=\"Masks on Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to Create U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Functions to Log Training of U-Net ##############\n",
    "def get_run_logdir(root_logdir, input_string):\n",
    "    import time\n",
    "    if not input_string:\n",
    "        run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    else:\n",
    "        run_id = os.path.join(\n",
    "            input_string, time.strftime(\"run_%Y_%m_%d-%H_%M_%S\"))\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "\n",
    "def create_logdir(modelName):\n",
    "    root_logdir = os.path.join(os.curdir, \"My_logs\")\n",
    "    run_logdir = get_run_logdir(root_logdir, modelName)\n",
    "    return run_logdir\n",
    "################################################################\n",
    "\n",
    "########## Custom Loss Function for Dice Coeffiecient ##########\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def tversky(y_true, y_pred, smooth=1, alpha=0.7):\n",
    "    y_true_pos = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_pos = tf.keras.backend.flatten(y_pred)\n",
    "    true_pos = tf.keras.backend.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.keras.backend.sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = tf.keras.backend.sum((1 - y_true_pos) * y_pred_pos)\n",
    "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n",
    "\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true, y_pred)\n",
    "\n",
    "\n",
    "def focal_tversky_loss(y_true, y_pred, gamma=4/3):\n",
    "    tv = tversky(y_true, y_pred)\n",
    "    return tf.keras.backend.pow((1 - tv), gamma)\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModelName = 'U-Net_V_' + Orientation\n",
    "MyLogdir = create_logdir(MyModelName)\n",
    "MyModelSaveRoot = os.path.join(os.curdir, \"TrainedModels\")\n",
    "MyModelSavePath = os.path.join(MyModelSaveRoot, MyModelName+\".h5\")\n",
    "\n",
    "print(MyLogdir)\n",
    "print(MyModelSavePath)\n",
    "print(MyModelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MyModel = UNet.UNet_Vanilla(input_shape=(256, 256, 1)).CreateUnet()\n",
    "MyModel.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                loss=dice_coef_loss, metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "steps_p_epoch = np.ceil(1000/batch_size)\n",
    "\n",
    "# Use small subset of data\n",
    "image_generator = image_datagen.flow(\n",
    "    X[0:1000, :, :, :], batch_size=batch_size, seed=seed)\n",
    "mask_generator = mask_datagen.flow(\n",
    "    y[0:1000, :, :, :], batch_size=batch_size, seed=seed)\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "# Use small subset of data\n",
    "lr_finder = LRFinder(min_lr=1e-5, max_lr=1e-2,\n",
    "                     steps_per_epoch=steps_p_epoch, epochs=3)\n",
    "MyModel.fit(train_generator, steps_per_epoch=steps_p_epoch,\n",
    "            epochs=3, verbose=1, callbacks=[lr_finder])\n",
    "lr_finder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger_cb = tf.keras.callbacks.CSVLogger(\n",
    "    os.path.join(MyModelSaveRoot, MyModelName+\".csv\"), append=True)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(MyModelSavePath,\n",
    "                                                   monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=15, restore_best_weights=True, monitor='val_loss')\n",
    "clr_triangular_cb = CyclicLR(\n",
    "    base_lr=1e-4, max_lr=1.8e-4, mode='triangular2', step_size=5*X.shape[0])\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(MyLogdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Compile Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer = \"Adam\"\n",
    "loss = \"dice_coef_loss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Training Patameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 20\n",
    "steps_p_epoch = np.ceil(X.shape[0]/batch_size)\n",
    "image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "mask_generator = mask_datagen.flow(y, batch_size=batch_size, seed=seed)\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MyModel.fit(train_generator, steps_per_epoch=steps_p_epoch, epochs=epochs, verbose=1, validation_data=(X_Val, y_Val),\n",
    "            callbacks=[checkpoint_cb, early_stopping_cb, clr_triangular_cb, tensorboard_cb, csv_logger_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_triangular_cb._reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MyModel.fit(train_generator, steps_per_epoch=steps_p_epoch, epochs=epochs, verbose=1, validation_data=(X_Val, y_Val),\n",
    "            callbacks=[checkpoint_cb, early_stopping_cb, clr_triangular_cb, tensorboard_cb, csv_logger_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModel.load_weights(MyModelSavePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Model Parameters to Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModelParameters_Strings = [\"ScanType\", \"n_Scans\",\n",
    "                             \"Orientation\", \"Optimizer\", \"Loss\", \"batch_size\", \"epochs\"]\n",
    "MyModelParameters_values = [ScanType, n_Scans,\n",
    "                            Orientation, Optimizer, loss, batch_size, epochs*2]\n",
    "\n",
    "TextFileName = MyModelName+\".txt\"\n",
    "TextFilePath = os.path.join(os.curdir, \"TrainedModels\", TextFileName)\n",
    "\n",
    "with open(TextFilePath, \"w\") as file:\n",
    "    file.write(\"Parameters for \" + MyModelName + \":\\n\\n\")\n",
    "    for parameter in enumerate(MyModelParameters_Strings):\n",
    "        file.write(parameter[1] + \": \" +\n",
    "                   str(MyModelParameters_values[parameter[0]])+\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Performance on Test Set\n",
    "## View Predicted Images Over Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    y_predict = MyModel.predict(X_Val, batch_size=10, verbose=1)\n",
    "except:\n",
    "    X_Val = np.squeeze(X_Val)\n",
    "    print(\"Error: Input to Model has to be 4D (x, y, x, 1)\")\n",
    "    print(\"Reshaping..\")\n",
    "    X_Val = np.expand_dims(X_Val, axis=3)\n",
    "    y_predict = MyModel.predict(X_Val, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_predict = np.squeeze(y_predict)\n",
    "X_Val = np.squeeze(X_Val)\n",
    "\n",
    "try:\n",
    "    X_Val = np.squeeze(X_Val)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    y_threshold = np.squeeze(y_threshold)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    y_Val = np.squeeze(y_Val)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "y_new = np.ma.masked_where(y_predict > 0, y_predict, copy=False)\n",
    "\n",
    "showCTMontageOverlay(IMG1=X_Val[300:400, :, :],\n",
    "                     IMG2=y_new[300:400, :, :], SIZE=25, SaveFig=True, save_fig_name=\"Predicted Masks on Actual Masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv(os.path.join(MyModelSaveRoot, MyModelName + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=set_size(subplots=(1, 2)))\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(5))\n",
    "\n",
    "axs[0].set_ylim((0.99, 1))\n",
    "axs[0].set_xlabel('Epoch', labelpad=10)\n",
    "axs[0].set_ylabel('Accuracy', labelpad=10)\n",
    "axs[0].plot(history.accuracy)\n",
    "\n",
    "axs[1].set_ylim((0.25, 0.5))\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].plot(history.loss)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "save_path = os.path.join(os.curdir, \"SavedFigures\")\n",
    "save_name = \"UNet_Vanilla_Accuracy_Loss\"\n",
    "plt.savefig(os.path.join(save_path, save_name+\".pdf\"), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.85px",
    "left": "-1347px",
    "right": "20px",
    "top": "256px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
